{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43200a7e",
   "metadata": {},
   "source": [
    "## MMA 860 Team Project: Predicting Housing Prices\n",
    "\n",
    "Team Istanbul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e3e1aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openpyxl\n",
    "# %matplotlib inline\n",
    "# %pip install statsmodels\n",
    "# %pip install scikit-learn seaborn\n",
    "# %pip install jupyter_contrib_nbextensions\n",
    "# %pip install --upgrade scikit-learn\n",
    "# %pip install lightgbm xgboost scikit-learn --quiet\n",
    "# %pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c3f8985",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-19T23:23:32.795114Z",
     "iopub.status.busy": "2025-04-19T23:23:32.794783Z",
     "iopub.status.idle": "2025-04-19T23:23:34.802884Z",
     "shell.execute_reply": "2025-04-19T23:23:34.801851Z"
    },
    "papermill": {
     "duration": 2.01369,
     "end_time": "2025-04-19T23:23:34.804955",
     "exception": false,
     "start_time": "2025-04-19T23:23:32.791265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "import statsmodels.imputation.mice as mice\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "from patsy import dmatrices\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44d1b4cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T23:23:34.810609Z",
     "iopub.status.busy": "2025-04-19T23:23:34.810210Z",
     "iopub.status.idle": "2025-04-19T23:25:19.776415Z",
     "shell.execute_reply": "2025-04-19T23:25:19.775162Z"
    },
    "papermill": {
     "duration": 104.970876,
     "end_time": "2025-04-19T23:25:19.778154",
     "exception": false,
     "start_time": "2025-04-19T23:23:34.807278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Converting data source to dataframes\n",
    "file_path_test  = \"test.csv\"\n",
    "file_path_train = \"train.csv\"\n",
    "\n",
    "test  = pd.read_csv(file_path_test)\n",
    "train = pd.read_csv(file_path_train)\n",
    "\n",
    "data = pd.concat([train, test], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9eca4",
   "metadata": {},
   "source": [
    "### Data Cleaning and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4c061e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill categorical with mode\n",
    "cat_cols = data.select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    data[col] = data[col].fillna(data[col].mode()[0])\n",
    "    lbl = LabelEncoder()\n",
    "    data[col] = lbl.fit_transform(data[col].astype(str))\n",
    "\n",
    "# Fill numerical with median\n",
    "num_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "for col in num_cols:\n",
    "    data[col] = data[col].fillna(data[col].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eb941f",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1af8d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining features for Bathrooms to reduce dimensions\n",
    "data['TotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']\n",
    "data['TotalBath'] = (data['FullBath'] + data['HalfBath'] * 0.5 +\n",
    "                     data['BsmtFullBath'] + data['BsmtHalfBath'] * 0.5)\n",
    "\n",
    "#Combining features for porches to reduce dimensions\n",
    "data['TotalPorchSF'] = (data['OpenPorchSF'] + data['EnclosedPorch'] +\n",
    "                        data['3SsnPorch'] + data['ScreenPorch'])\n",
    "\n",
    "#Converting numerical features to Categorical (binary features make presence/effect of features more explicit)\n",
    "data['HasPool'] = (data['PoolArea'] > 0).astype(int)\n",
    "data['HasGarage'] = (data['GarageArea'] > 0).astype(int)\n",
    "data['HasFireplace'] = (data['Fireplaces'] > 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf38b93",
   "metadata": {},
   "source": [
    "### Regression Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f4d96a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train & test sets\n",
    "train_clean = data[:len(train)].copy()\n",
    "test_clean = data[len(train):].copy()\n",
    "train_clean['SalePrice'] = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "983390bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log transforming target to reduce skewness in data\n",
    "y = np.log1p(train_clean['SalePrice'])\n",
    "\n",
    "X = train_clean.drop(['Id', 'SalePrice'], axis=1)\n",
    "X_test = test_clean.drop(['Id', 'SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5925f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining base models\n",
    "#Using pipeline method to chain steps & uses features in similar scaling\n",
    "ridge = make_pipeline(RobustScaler(), Ridge(alpha=15))\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha=0.0005))\n",
    "\n",
    "#Usring XBG & LGB models to handle complex feature and target relationships\n",
    "xgb = XGBRegressor(n_estimators=1000, learning_rate=0.05, max_depth=3,\n",
    "                   subsample=0.7, colsample_bytree=0.7, random_state=42)\n",
    "lgbm = LGBMRegressor(objective='regression', num_leaves=5, learning_rate=0.05,\n",
    "                     n_estimators=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66302c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking all models\n",
    "stacked_model = StackingRegressor(\n",
    "    estimators=[('ridge', ridge), ('lasso', lasso), ('xgb', xgb), ('lgbm', lgbm)],\n",
    "    final_estimator=Ridge(alpha=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397f8116",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "270dced0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3801\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score 12.025324\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3396\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.022870\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3446\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.023779\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3432\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.021039\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3533\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.034647\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3522\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.024284\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3782\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score 12.028659\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3418\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.025859\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3444\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.030148\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3416\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.022659\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3446\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.037116\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3422\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.027511\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3789\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score 12.021956\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3410\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.015367\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3424\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.021057\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3432\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.021047\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3436\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.033321\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3423\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.018990\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3787\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score 12.019795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3387\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.016110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3430\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.018241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3422\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.013938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3444\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.029955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3427\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.020731\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3779\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.020663\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3383\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.016942\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3505\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.021413\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3399\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.017308\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.029827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3509\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.017828\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3779\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.026297\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3406\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.024564\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3433\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.025467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3407\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.022524\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3428\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.034159\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3421\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.024774\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3788\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score 12.029436\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3415\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.027996\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3431\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.026436\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3411\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 12.028983\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3434\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.035053\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3430\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.028714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3786\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score 12.022123\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3410\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.020183\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3432\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.025919\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3434\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.015815\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3518\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.028466\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3427\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.020234\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3788\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score 12.023877\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3404\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.022132\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3425\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.024812\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3419\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.017624\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3430\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.033702\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3419\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.021120\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3797\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score 12.022444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3415\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.020117\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3437\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.020570\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3427\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.021715\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3521\n",
      "[LightGBM] [Info] Number of data points in the train set: 1051, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 12.027047\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3421\n",
      "[LightGBM] [Info] Number of data points in the train set: 1052, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.022770\n",
      "📉 Stacked Model CV RMSE: 0.12315\n"
     ]
    }
   ],
   "source": [
    "#Calculating Root Mean Square Error \n",
    "def rmse_cv(model):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    rmse = -cross_val_score(model, X, y, scoring=\"neg_root_mean_squared_error\", cv=kf)\n",
    "    return rmse.mean()\n",
    "\n",
    "print(f\"Stacked Model CV RMSE: {rmse_cv(stacked_model):.5f}/n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e189ef4",
   "metadata": {},
   "source": [
    "### Predict Values for Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abe26978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3889\n",
      "[LightGBM] [Info] Number of data points in the train set: 1460, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score 12.024057\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3596\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.021409\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3611\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.023288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3609\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score 12.020737\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3626\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score 12.032956\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3612\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score 12.021897\n"
     ]
    }
   ],
   "source": [
    "#Fit and predict\n",
    "stacked_model.fit(X, y)\n",
    "final_preds = np.expm1(stacked_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17b73102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved: submission.csv\n"
     ]
    }
   ],
   "source": [
    "#Export csv with predictions for comptetion submission\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test['Id'],\n",
    "    'SalePrice': final_preds\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved: submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868283,
     "sourceId": 5407,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 113.073528,
   "end_time": "2025-04-19T23:25:20.906900",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-19T23:23:27.833372",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
